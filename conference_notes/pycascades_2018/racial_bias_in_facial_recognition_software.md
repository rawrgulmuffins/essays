# Racial Bias in Facial Recognition Software (Stephanie Kim)
* Racism in a resume goo.gl/RJmfYh
* Facial recognition software was used to guess the chance of re-offending.
There have been cases where the software was biased in favor of stating black
inmates are more likely to offend dispite other data disagreeing.
* Skin color isn't actually a training feature for facebooks facial recognition.
(OpenFace) This is because the algorithm chooses to reduce all colors to grey
scale. 
